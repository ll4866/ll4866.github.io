---
permalink: /dln/
title: "Digital Literacy Narrative"
author_profile: false
categories:
  - DNL
tags:
  - Done
toc: true
toc_label: "Digital Litaracy Narrative"
toc_sticky: true
---
**Step 1:** focuses on personalizing a provided text to reflect my own digital literacies and the skills I aim to develop this semester. The goal is to revise the Generated Response (by GPT-4o, 30 Jan 25) to reflect my perspective while keeping it around 750 words.

**Phase 1 Due date:** 8 February 2025.
<br/>
**Revision 1 Due date:** 22 March 2025.
<br/>
**Revision 2 Due date:** 11 May 2025.
{: .notice}

<!-- Collapsible -->
<details>
<summary> Prompt: </summary>
Write a 750 word reflection on digital literacy from the perspective of a 20 year old university student at a liberal arts university. Include strategies they might already know how to employ in their daily and academic lives for content creation, social interaction, as well as any platforms or software they use for research data management as well as data manipulation and analysis. Consider the different skill sets in the room given all the interdisciplinary majors ( in different fields such as Computer Science, Interactive Media, Film and New Media, Literature or Creative Writing, Art and Art History). Reflect on how digital humanities might offer new horizons on what they are studying, how collaboration might offer new avenues for developing their “computational thinking” that is in the sense of Berry and Fagerjord (A cognitive practice involving practical wisdom and reflection on computation) and how they can learn about new ways of approaching data and the world of AI. Offer critical reflection on your current abilities, what you are what you are discovering in the course as well as what kinds of new ways of thinking you would like to explore.*
</details>

### Navigating Digital Literacy as an Interactive Media Arts Student
My digital literacy journey at NYU Shanghai has been profoundly shaped by two transformative projects: the AI-generated cat image classification and the Zanzibar Gazette historical data extraction. As Lauren Klein et al. (2025) argue in "Provocations from the Humanities for Generative AI Research," these experiences revealed how computational tools don't merely assist humanistic inquiry but actively reshape epistemological practices. Working simultaneously with cutting-edge AI systems and century-old newspapers, I've developed what Drucker (2021) terms "humanistic computational literacy"—the ability to critically interrogate how technologies structure knowledge.

### The Interdisciplinary Digital Workshop
The Zanzibar Gazette project demanded skills spanning my entire toolkit: from Figma's precision interface design (for data cleaning dashboards) to Unity's spatial logic (for Kepler.gl visualizations). This interdisciplinary need echoes Manoff's (2020) observation that digital humanities work exists at the "nexus of computational methods and humanistic interpretation." When correcting OCR errors in shipping manifests, I applied the same attention to detail cultivated in DaVinci Resolve's color grading workflows, recognizing—as Arnold and Tilton (2019) emphasize in Distant Viewing—that data cleaning is never neutral but always interpretive.

### From Colonial Archives to AI Classifications
Processing the Gazette's shipping records through Gemini and DeepSeek became a practical test of Klein's principle that "bigger AI models aren't necessarily better." While Gemini failed to handle CSV files or expand ditto marks, DeepSeek's sophisticated pattern recognition—able to infer missing port names like "Dar es Salaam" from contextual clues—demonstrated what Underwood (2019) calls "computational hermeneutics." This mirrored findings from my cat image project, where InceptionV3 and SqueezeNet each revealed different perceptual biases in classifying visual content. Both projects confirmed Liu's (2021) warning that "all data is cooked," requiring constant vigilance against algorithmic smoothing of historical nuance.

### The Ethics of Digital Reconstruction
The pivotal moment in the Gazette project—discovering we'd cropped out warships and dhows from initial scans—resonated with Risam's (2018) concept of "colonial data violence." Our subsequent correction process, creating separate visualization layers for different vessel types in Kepler.gl, implemented Drucker's (2021) call for "performative data visualization" that surfaces marginalized narratives. This ethical framework directly informed my cat image classification work, where I deliberately included meme and surreal categories often excluded from standard training datasets.

### Computational Thinking as Historical Practice
Standardizing the Gazette's ship prefixes (S.S. vs C.S.) and port names revealed how, as Gitelman and Jackson (2013) note, "raw data is an oxymoron." The iterative process—comparing AI outputs against original scans, then adjusting DeepSeek prompts—mirrored my cat project's hybrid methodology combining CLIP analysis with manual tagging. Both projects exemplified what Svensson (2016) terms "humanities infrastructure," where technical work becomes inseparable from intellectual labor. The Gazette's temporal data preparation, requiring meticulous reconstruction of incomplete dates, particularly demonstrated Klein's argument about the importance of "contextual integrity" in historical datasets.

### Transformative Encounters with Imperfection
Working with the Gazette's OCR errors ("Wami" vs "Wani") and my cat project's misclassifications (humorous images labeled surreal) cultivated what Nowviskie (2019) calls "resistance to closure"—the ability to value digital imperfections as sites of critical inquiry. This mindset shift, documented in my assignment's detailed error logs, transformed my approach to tools like Kepler.gl from seeing them as definitive solutions to understanding them as what Drucker terms "speculative instruments." The dhow traffic visualizations, corrected through cross-referencing Encyclopaedia Britannica's German East Africa records, became a case study in what Warwick (2012) describes as "the interplay between digital remediation and historical imagination."

### Future Directions in Critical DH Praxis
Moving forward, I aim to apply these lessons to oral history digitization, extending the Gazette project's hybrid methodology. As the cat classification revealed gaps in AI's understanding of humor and irony—and the Gazette exposed colonial biases in maritime records—I'm particularly interested in developing what Risam (2018) calls "postcolonial digital humanities" approaches. This means building on Klein's provocation to develop "AI systems that surface rather than suppress contextual complexity," whether working with historical newspapers or contemporary image datasets.

Used GPT to refine my text
<br/>
**✅ Ready for grading**
{: .notice}